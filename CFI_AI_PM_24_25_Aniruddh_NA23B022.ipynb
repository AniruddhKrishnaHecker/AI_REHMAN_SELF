{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGFJ1pQsP8VN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVmsGWUFd-tP"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMJ4av3_YGjM",
        "outputId": "8a004435-5bc6-4008-d883-1c2aeb88c4fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUT0FSfTbvoc"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "!pip3 install pyprind\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3APxWObeA_c"
      },
      "source": [
        "# Instructions\n",
        "\n",
        "* Clone the notebook to your drive.\n",
        "* The notebook has to be submitted in the form of a link giving us **view access**. Share this link in your application.\n",
        "\n",
        "* If you still have any queries, you can reach out to the [core team](https://www.notion.so/Club-Contacts-70a4823e0ae34f35a0aa5d479e449915)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0ojuzzfedsb"
      },
      "source": [
        "# Common Technical Questionnaire\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFnXRXAWVSkZ"
      },
      "source": [
        "### Question 1\n",
        "\n",
        "Supervised learning is a type of machine learning where the inputs and outputs are mapped through\n",
        "a family of equations, the machine learning model essentially picks the right curve to fit the data.\n",
        "Quantile Regression is a type of supervised learning technique used in statistics and economics. One\n",
        "advantage of quantile regression relative to ordinary least squares regression is that the quantile\n",
        "regression estimates are more robust against outliers in the response measurements.\n",
        "\n",
        "QuantileLossτ (y, ˆy) =\n",
        "{\n",
        "\n",
        "                           τ · (y − ˆy) if y > ˆy\n",
        "\n",
        "                          (1 − τ ) · (ˆy − y) if y ≤ ˆy\n",
        "}\n",
        "\n",
        "where τ is Quantile whose value lies between 0 and 1.\n",
        "Please use this template provided and make changes accordingly for this question alone.\n",
        "Implement a simple Neural Network consisting of 4 nodes, one hidden layer consisting of 5 nodes\n",
        "and output layer consisting of two nodes. Perform quantile regression on the model and observe\n",
        "the loss.\n",
        "**Bonus: Play around with the value of τ to find what value achieves convergence quicker.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bKBykeUZtMq"
      },
      "source": [
        "An example implementation of a simple manual neural network is provided. You may use this as inspiration to complete the task at hand."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5YhkW3jE58O"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnVdvfk-Zsyr",
        "outputId": "5f050153-4fe0-4941-b590-973ab573ed40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.3883731365203857\n",
            "3.3228299617767334\n",
            "3.258127212524414\n"
          ]
        }
      ],
      "source": [
        "# Initializing the Parameters and the Variables\n",
        "# y = a*x + b\n",
        "\n",
        "x = torch.rand((2, 4), requires_grad=False)\n",
        "y = torch.rand((2, 2), requires_grad=False)\n",
        "\n",
        "a0 = torch.rand((4, 5), requires_grad=True)     #For the hidden layer\n",
        "b0 = torch.rand((2, 5), requires_grad=True)\n",
        "\n",
        "a1 = torch.rand((5, 2), requires_grad=True)     #For the output layer.    Fill in the dimensions appropriately\n",
        "b1 = torch.rand((2, 2), requires_grad=True)\n",
        "ReLU=nn.ReLU()\n",
        "# Forward Pass 1\n",
        "y_1 = x@a0+ b0\n",
        "y_pred1=y_1@a1+b1\n",
        "z1=ReLU(y_pred1)                                    #Fill in the matrix multiplication equation\n",
        "\n",
        "tau=0.2\n",
        "def loss_function(z, y):\n",
        "    e = y - z\n",
        "    return torch.max((tau - 1) * e, tau * e).mean()\n",
        "\n",
        "# Computing Loss\n",
        "loss = loss_function(z1, y)\n",
        "print(loss.item())\n",
        "\n",
        "# Back Propogation\n",
        "loss.backward()\n",
        "\n",
        "# Updating Gradients\n",
        "with torch.no_grad():\n",
        "    a0 -= 0.01 * a0.grad\n",
        "    b0 -= 0.01 * b0.grad\n",
        "    a1 -= 0.01 * a1.grad\n",
        "    b1 -= 0.01 * b1.grad\n",
        "\n",
        "    # Zeroing out gradients for the next iteration\n",
        "    a0.grad.zero_()\n",
        "    b0.grad.zero_()\n",
        "    a1.grad.zero_()\n",
        "    b1.grad.zero_()\n",
        "\n",
        "# Forward Pass 2\n",
        "y_2 = x@a0+ b0\n",
        "y_pred2= y_2@a1+b1                                      #Fill in the matrix multiplication equation\n",
        "z2=ReLU(y_pred2)\n",
        "# Computing Loss\n",
        "loss = loss_function(z2, y)\n",
        "print(loss.item())\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "# Updating Gradients\n",
        "with torch.no_grad():\n",
        "    a0 -= 0.01 * a0.grad\n",
        "    b0 -= 0.01 * b0.grad\n",
        "    a1 -= 0.01 * a1.grad\n",
        "    b1 -= 0.01 * b1.grad\n",
        "\n",
        "    # Zeroing out gradients for the next iteration\n",
        "    a0.grad.zero_()\n",
        "    b0.grad.zero_()\n",
        "    a1.grad.zero_()\n",
        "    b1.grad.zero_()\n",
        "\n",
        "# Forward Pass 3\n",
        "y_3 =  x@a0+ b0                      #Fill in the matrix multiplication equation\n",
        "y_pred3=y_3@a1+b1\n",
        "z3=ReLU(y_pred3)\n",
        "# Computing Loss\n",
        "loss = loss_function(z3, y)\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izhl-9Wta_uu"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
